"""
VoiceTrainer for VocalTwin – extracts a *tone-color embedding* (speaker
embedding) from one or more MP3 recordings using **OpenVoice V2** and
saves it as the project checkpoint.

Instead of re-training an entire TTS model, we simply compute the
embedding vector that the ToneColorConverter can apply to any base voice
generated by MeloTTS.

Directory expectations
----------------------
checkpoints_v2/
    ├── converter/
    │   ├── config.json
    │   └── checkpoint.pth
    └── base_speakers/        # needed later by synthesizer
        └── ses/
            └── *.pth

Author: you
"""

from __future__ import annotations

import logging
from pathlib import Path
from typing import List

import torch
from openvoice import se_extractor
from openvoice.api import ToneColorConverter

logger = logging.getLogger(__name__)
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s | %(levelname)s | %(message)s"
)


class VoiceTrainer:
    """Extracts & stores a target-speaker embedding."""

    def __init__(
            self,
            ckpt_converter_dir: Path | str = Path("checkpoints_v2/converter"),
            device: str | None = None,
    ) -> None:
        self.ckpt_converter_dir = Path(ckpt_converter_dir)
        self.device = (
            device
            if device is not None
            else ("cuda:0" if torch.cuda.is_available() else "cpu")
        )

        # Load the OpenVoice tone-colour converter (needed for SE extraction)
        config_path = self.ckpt_converter_dir / "config.json"
        pth_path = self.ckpt_converter_dir / "checkpoint.pth"

        if not (config_path.exists() and pth_path.exists()):
            raise FileNotFoundError(
                f"❌  OpenVoiceV2 converter checkpoints not found in "
                f"{self.ckpt_converter_dir}.  Download them first."
            )

        self.converter = ToneColorConverter(str(config_path), device=self.device)
        self.converter.load_ckpt(str(pth_path))

        logger.debug(
            "VoiceTrainer initialised (device=%s, ckpt_converter_dir=%s)",
            self.device,
            self.ckpt_converter_dir,
        )

    # ------------------------------------------------------------------ #
    # Public API
    # ------------------------------------------------------------------ #

    def train(self, audio_dir: Path | str, checkpoint_dir: Path | str) -> None:
        """
        Extract a robust speaker embedding from all MP3 files in *audio_dir*
        and save it to *checkpoint_dir/target_se.pth*.
        """

        audio_dir = Path(audio_dir)
        checkpoint_dir = Path(checkpoint_dir)
        checkpoint_dir.mkdir(parents=True, exist_ok=True)

        mp3s = self._collect_mp3s(audio_dir)
        if not mp3s:
            logger.error("No MP3 files found in %s – aborting.", audio_dir)
            return

        logger.info("🔍 Found %d MP3 recordings – extracting embeddings ...", len(mp3s))
        embeddings = [self._extract_se(p) for p in mp3s]

        # Average to obtain a single, noise-robust vector
        target_se = torch.stack(embeddings).mean(dim=0)
        ckpt_path = checkpoint_dir / "target_se.pth"
        torch.save({"se": target_se}, ckpt_path)

        logger.info("✅ Speaker embedding saved to %s", ckpt_path)

    # ------------------------------------------------------------------ #
    # Helpers
    # ------------------------------------------------------------------ #

    @staticmethod
    def _collect_mp3s(root: Path) -> List[Path]:
        """Recursively gather *.mp3 files."""
        return [p for p in root.rglob("*.mp3") if p.is_file()]

    def _extract_se(self, audio_path: Path) -> torch.Tensor:
        """Return the speaker-embedding for *audio_path*."""
        se, _ = se_extractor.get_se(
            str(audio_path),
            self.converter,
            vad=True,  # trim leading/trailing silence for cleaner SE
        )
        logger.debug(" ↳ extracted from %s", audio_path.name)
        return se
